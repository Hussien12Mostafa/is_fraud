{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "230BdHmpBH08"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The system cannot find the path specified.\n",
            "'wget' is not recognized as an internal or external command,\n",
            "operable program or batch file.\n",
            "tar: Error opening archive: Failed to open 'spark-3.0.1-bin-hadoop3.2.tgz'\n",
            "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\pc\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\pc\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n"
          ]
        },
        {
          "ename": "Exception",
          "evalue": "Unable to find py4j in /kaggle/working/spark-3.0.1-bin-hadoop3.2\\python, your SPARK_HOME may not be configured correctly",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "File \u001b[1;32mc:\\Users\\pc\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\findspark.py:159\u001b[0m, in \u001b[0;36minit\u001b[1;34m(spark_home, python_path, edit_rc, edit_profile)\u001b[0m\n\u001b[0;32m    158\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 159\u001b[0m     py4j \u001b[39m=\u001b[39m glob(os\u001b[39m.\u001b[39;49mpath\u001b[39m.\u001b[39;49mjoin(spark_python, \u001b[39m\"\u001b[39;49m\u001b[39mlib\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mpy4j-*.zip\u001b[39;49m\u001b[39m\"\u001b[39;49m))[\u001b[39m0\u001b[39;49m]\n\u001b[0;32m    160\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mIndexError\u001b[39;00m:\n",
            "\u001b[1;31mIndexError\u001b[0m: list index out of range",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[1;31mException\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32me:\\projects\\is_fraud\\bigDataProject .ipynb Cell 1\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/projects/is_fraud/bigDataProject%20.ipynb#X11sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m os\u001b[39m.\u001b[39menviron[\u001b[39m\"\u001b[39m\u001b[39mSPARK_HOME\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m/kaggle/working/spark-3.0.1-bin-hadoop3.2\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/projects/is_fraud/bigDataProject%20.ipynb#X11sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mfindspark\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/e%3A/projects/is_fraud/bigDataProject%20.ipynb#X11sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m findspark\u001b[39m.\u001b[39;49minit()\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/projects/is_fraud/bigDataProject%20.ipynb#X11sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpyspark\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msql\u001b[39;00m \u001b[39mimport\u001b[39;00m SparkSession\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/projects/is_fraud/bigDataProject%20.ipynb#X11sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpyspark\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\pc\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\findspark.py:161\u001b[0m, in \u001b[0;36minit\u001b[1;34m(spark_home, python_path, edit_rc, edit_profile)\u001b[0m\n\u001b[0;32m    159\u001b[0m         py4j \u001b[39m=\u001b[39m glob(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(spark_python, \u001b[39m\"\u001b[39m\u001b[39mlib\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mpy4j-*.zip\u001b[39m\u001b[39m\"\u001b[39m))[\u001b[39m0\u001b[39m]\n\u001b[0;32m    160\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mIndexError\u001b[39;00m:\n\u001b[1;32m--> 161\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mException\u001b[39;00m(\n\u001b[0;32m    162\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mUnable to find py4j in \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m, your SPARK_HOME may not be configured correctly\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m    163\u001b[0m                 spark_python\n\u001b[0;32m    164\u001b[0m             )\n\u001b[0;32m    165\u001b[0m         )\n\u001b[0;32m    166\u001b[0m     sys\u001b[39m.\u001b[39mpath[:\u001b[39m0\u001b[39m] \u001b[39m=\u001b[39m sys_path \u001b[39m=\u001b[39m [spark_python, py4j]\n\u001b[0;32m    167\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    168\u001b[0m     \u001b[39m# already imported, no need to patch sys.path\u001b[39;00m\n",
            "\u001b[1;31mException\u001b[0m: Unable to find py4j in /kaggle/working/spark-3.0.1-bin-hadoop3.2\\python, your SPARK_HOME may not be configured correctly"
          ]
        }
      ],
      "source": [
        "# here give error you should install spark in your device and conect with it   or same note book but in kaggle \n",
        "# https://www.kaggle.com/code/hussienawad/is-fraud-analysis\n",
        "\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q https://archive.apache.org/dist/spark/spark-3.0.1/spark-3.0.1-bin-hadoop3.2.tgz\n",
        "!tar xf spark-3.0.1-bin-hadoop3.2.tgz\n",
        "!pip install -q findspark\n",
        "import os\n",
        "\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/kaggle/working/spark-3.0.1-bin-hadoop3.2\"\n",
        "import findspark\n",
        "\n",
        "findspark.init()\n",
        "from pyspark.sql import SparkSession\n",
        "import pyspark\n",
        "spark = SparkSession.builder\\\n",
        "        .master(\"local\")\\\n",
        "        .appName(\"Kaggle\")\\\n",
        "        .config('spark.ui.port', '4050')\\\n",
        "        .getOrCreate()\n",
        "sc = spark.sparkContext\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x4NV7hHiCC0O"
      },
      "outputs": [],
      "source": [
        "sc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BvAZZ8wUCFRm"
      },
      "outputs": [],
      "source": [
        "spark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GPSMGm1FCIUK"
      },
      "outputs": [],
      "source": [
        "from IPython.display import display, HTML\n",
        "display(HTML(\"<style>pre { white-space: pre !important; }</style>\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u3E_DeHXRMw2"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession.builder.appName(\"example\").config(\"spark.sql.legacy.timeParserPolicy\", \"LEGACY\").getOrCreate()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Tp-uebaCMzt"
      },
      "outputs": [],
      "source": [
        "df = spark.read.csv(\"/content/fraudTrain.csv\",inferSchema=True, header=True)\n",
        "df.show(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5KRSvKcLZPZf"
      },
      "outputs": [],
      "source": [
        "analysis, val_data, test_data = df.randomSplit([0.1, 0.7, 0.2], seed=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K-T9Cs7XlMBH"
      },
      "outputs": [],
      "source": [
        "import plotly.express as px\n",
        "from pyspark.sql.functions import count\n",
        "fraud_counts = analysis.groupBy(\"is_fraud\").agg(count(\"*\").alias(\"count\"))\n",
        "\n",
        "print(fraud_counts.collect())\n",
        "# collect counts as list\n",
        "fraud_or_not = [int(row[\"count\"]) for row in fraud_counts.collect()]\n",
        "labels = [\"Fraud\",\"notFraud\"]\n",
        "\n",
        "# create pie chart\n",
        "fig = px.pie(values=fraud_or_not, names=labels, width=700, height=400, color_discrete_sequence=[\"skyblue\",\"black\"], title=\"notFraud vs Fraud\")\n",
        "fig.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YzZLxwQ1fOaf"
      },
      "outputs": [],
      "source": [
        "counts = analysis.groupBy(\"gender\").agg(count(\"*\").alias(\"count\"))\n",
        "print(counts.collect())\n",
        "# collect counts as list\n",
        "count = [int(row[\"count\"]) for row in counts.collect()]\n",
        "labels = [\"F\",\"M\"]\n",
        "\n",
        "# create pie chart\n",
        "fig = px.pie(values=count, names=labels, width=700, height=400, color_discrete_sequence=[\"skyblue\",\"black\"], title=\"F vs M\")\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L_5SgBcrmfBe"
      },
      "outputs": [],
      "source": [
        "unique_values = analysis.select(\"city\").distinct().collect()\n",
        "unique_values_list = [row[\"city\"] for row in unique_values]\n",
        "print(len(unique_values_list))\n",
        "unique_values_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Q_oKOhzegHK"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql.functions import to_timestamp\n",
        "df = df.withColumn('timestamp_col', to_timestamp('trans_date_trans_time', 'yyyy-MM-dd HH:mm:ss'))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SAWvNa2qgGt4"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql.functions import max, min\n",
        "\n",
        "# assume you have a dataframe df with a column 'datetime_col' of datetime type\n",
        "max_date = df.select(max('timestamp_col')).collect()[0][0]\n",
        "min_date = df.select(min('timestamp_col')).collect()[0][0]\n",
        "\n",
        "print(\"Maximum datetime value:\", max_date)\n",
        "print(\"Minimum datetime value:\", min_date)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "grntGgs1ge2I"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql.functions import col\n",
        "\n",
        "# Assuming your DataFrame is named 'df', you can get unique values for columns 'col1' and 'col2' as follows\n",
        "unique_values = analysis.select(col(\"first\"), col(\"last\")).distinct()\n",
        "unique_values.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ugU7s5Ixg-Pq"
      },
      "outputs": [],
      "source": [
        "unique_values.count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SYK0LmW49-jx"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql.functions import col\n",
        "import plotly.express as px\n",
        "from pyspark.sql.functions import count\n",
        "df_filtered = df.filter(col('is_fraud') ==1)\n",
        "col2_extracted = df_filtered.select('amt')\n",
        "col2_extracted.agg(count(\"*\").alias(\"count\")).collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JYTVEhitEWOw"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql.functions import sum\n",
        "col2_extracted.agg(sum(\"amt\")).collect()[0][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D82RtDiZ-EY2"
      },
      "outputs": [],
      "source": [
        "col_rdd = col2_extracted.rdd.map(lambda row: row[0])\n",
        "\n",
        "# define function to map each partition of RDD to a tuple of (sum, count)\n",
        "def map_partition(iter):\n",
        "    sum = 0\n",
        "    count = 0\n",
        "    for val in iter:\n",
        "        sum += val\n",
        "        count += 1\n",
        "        if count == 5000:\n",
        "            yield (sum, count)\n",
        "            sum = 0\n",
        "            count = 0\n",
        "    if count > 0:\n",
        "        yield (sum, count)\n",
        "\n",
        "# map each partition of RDD to a tuple of (sum, count)\n",
        "mapped_rdd = col_rdd.mapPartitions(map_partition)\n",
        "\n",
        "# reduce by summing the sum values and counting the count values\n",
        "(sum, count) = mapped_rdd.reduce(lambda x, y: (x[0] + y[0], x[1] + y[1]))\n",
        "\n",
        "# calculate mean\n",
        "mean = sum / count\n",
        "\n",
        "print(\"Mean: \", mean)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yUkPmvqgldf1"
      },
      "outputs": [],
      "source": [
        "amt = analysis.select(col(\"amt\"))\n",
        "amt.show(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eabcGOudrBUr"
      },
      "outputs": [],
      "source": [
        "col_rdd = amt.rdd.map(lambda row: row[0])\n",
        "\n",
        "# define function to map each partition of RDD to a tuple of (sum, count)\n",
        "def map_partition(iter):\n",
        "    sum = 0\n",
        "    count = 0\n",
        "    for val in iter:\n",
        "        sum += val\n",
        "        count += 1\n",
        "        if count == 10000:\n",
        "            yield (sum, count)\n",
        "            sum = 0\n",
        "            count = 0\n",
        "    if count > 0:\n",
        "        yield (sum, count)\n",
        "\n",
        "# map each partition of RDD to a tuple of (sum, count)\n",
        "mapped_rdd = col_rdd.mapPartitions(map_partition)\n",
        "\n",
        "# reduce by summing the sum values and counting the count values\n",
        "(sum, count) = mapped_rdd.reduce(lambda x, y: (x[0] + y[0], x[1] + y[1]))\n",
        "\n",
        "# calculate mean\n",
        "mean = sum / count\n",
        "\n",
        "print(\"Mean: \", mean)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7TF5IcSmCejY"
      },
      "outputs": [],
      "source": [
        "df.printSchema()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FCya91JpCmja"
      },
      "outputs": [],
      "source": [
        "deduped_df = df.dropDuplicates()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fHXy7o_QJhlE"
      },
      "outputs": [],
      "source": [
        "import pyspark.sql.functions as fn\n",
        "from pyspark.sql.functions import *\n",
        "from pyspark.ml.feature import OneHotEncoder, StringIndexer, VectorAssembler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PkwLSTeUJHZ_"
      },
      "outputs": [],
      "source": [
        "def stringIndexer(colName,newName,df):\n",
        "  stringIndexer = StringIndexer(inputCol=colName, outputCol=newName)\n",
        "  model = stringIndexer.fit(df)\n",
        "  indexed = model.transform(df)\n",
        "  return indexed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7MdtkbSXJTJP"
      },
      "outputs": [],
      "source": [
        "def oneHotEncoder(colName,newName,df):\n",
        "  encoder = OneHotEncoder(inputCol=colName, outputCol=newName)\n",
        "  encoded = encoder.fit(df).transform(df)\n",
        "  return encoded"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i37k8Rh1Cvm_"
      },
      "outputs": [],
      "source": [
        "df_m=stringIndexer(\"merchant\",\"merchantIndex\",deduped_df)\n",
        "df_m=oneHotEncoder(\"merchantIndex\",\"merchantVec\",df_m)\n",
        "df_m=stringIndexer(\"category\",\"categoryIndex\",df_m)\n",
        "df_m=oneHotEncoder(\"categoryIndex\",\"categoryVec\",df_m)\n",
        "df_m=stringIndexer(\"gender\",\"genderIndex\",df_m)\n",
        "df_m=oneHotEncoder(\"genderIndex\",\"genderVec\",df_m)\n",
        "df_m=stringIndexer(\"job\",\"jobIndex\",df_m)\n",
        "df_m=oneHotEncoder(\"jobIndex\",\"jobVec\",df_m)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F3dRlckwDfgm"
      },
      "outputs": [],
      "source": [
        "df_m.show(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1lN5YBJbHol0"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql.functions import to_date\n",
        "from pyspark.sql.functions import to_timestamp, hour\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RhxTnfepNJCg"
      },
      "outputs": [],
      "source": [
        "df_m = df_m.withColumn('timestamp_col', to_timestamp('trans_date_trans_time', 'yyyy-MM-dd HH:mm:ss'))\n",
        "df_m = df_m.withColumn('hour_col', hour('timestamp_col'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pUET_69ONbvK"
      },
      "source": [
        "choose col use to train\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VtIroutGNbQA"
      },
      "outputs": [],
      "source": [
        "assembler = VectorAssembler(inputCols=[\"amt\", \"zip\", \"city_pop\",\"unix_time\",\"merch_lat\",\"merch_long\",\"hour_col\",\"merchantVec\",\"categoryVec\",\"genderVec\",\"jobVec\"], outputCol=\"features\")\n",
        "\n",
        "X = assembler.transform(df_m)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "72UveZRXOKwb"
      },
      "outputs": [],
      "source": [
        "X.show(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o8EgnS-WOaV5"
      },
      "outputs": [],
      "source": [
        "trainDF,testDF = X.randomSplit([.8,.2],seed=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fD0UfZTVlwnp"
      },
      "outputs": [],
      "source": [
        "fea_Train=trainDF.select(col(\"amt\"),col(\"zip\"),col(\"city_pop\"),col(\"unix_time\"),col(\"merch_lat\"),col(\"merch_long\"),col(\"hour_col\"),col(\"merchantIndex\"),col(\"categoryIndex\"),col(\"genderIndex\"),col(\"jobIndex\"),col(\"is_fraud\"))\n",
        "fea_test=testDF.select(col(\"amt\"),col(\"zip\"),col(\"city_pop\"),col(\"unix_time\"),col(\"merch_lat\"),col(\"merch_long\"),col(\"hour_col\"),col(\"merchantIndex\"),col(\"categoryIndex\"),col(\"genderIndex\"),col(\"jobIndex\"),col(\"is_fraud\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bjrFEgLDnsr3"
      },
      "outputs": [],
      "source": [
        "\n",
        "train_rdd = fea_Train.rdd.map(lambda row: list(row))\n",
        "# Define a function to compute the distance between two points\n",
        "def distance(x, y):\n",
        "    e=0\n",
        "    for i in range(len(x)-1):\n",
        "        e+=(float(x[i]) - float(y[i]))**2 \n",
        "    return e\n",
        "\n",
        "# Define a function to map each test point to its k nearest neighbors in the training data\n",
        "def map_partition(iter, param):\n",
        "    # count=0\n",
        "    # for i in iter:\n",
        "    #   count+=1\n",
        "    #   if count==10:\n",
        "\n",
        "    #     yield (i, \"eee\")\n",
        "    #     count=0\n",
        "    # if count>0:\n",
        "    #   yield (\"iter\", \"eee\")\n",
        "    \n",
        "    count = 0\n",
        "    l={}\n",
        "    \n",
        "    for val in iter:\n",
        "        \n",
        "          d=distance(t,val)\n",
        "          l[d]=val[11]\n",
        "    \n",
        "          count += 1\n",
        "          if count == 10000:\n",
        "              sorted_list = sorted(l.keys())[:5]\n",
        "              out={}\n",
        "              for s in sorted_list:\n",
        "                out[s]=l[s]\n",
        "              yield (param, out)\n",
        "              count = 0\n",
        "    sorted_list = sorted(l.keys())[:5]\n",
        "    out={}\n",
        "    for s in sorted_list:\n",
        "      out[s]=l[s]\n",
        "    if count >0:\n",
        "        yield (param, out)\n",
        "def knn_reducer(x, y):\n",
        "    r={}\n",
        "    if x[0]==y[0]:\n",
        "      x[1].update(y[1])\n",
        "\n",
        "    return x\n",
        "# Define a function to reduce the nearest neighbors from each partition\n",
        "# def knn_reducer(x, y):\n",
        "#     merged = sorted(x + y)[:k]\n",
        "#     return merged\n",
        "\n",
        "\n",
        "\n",
        "# Map each test data point to its k nearest neighbors in the training data\n",
        "predicted=[]\n",
        "truePred=[]\n",
        "for t in fea_test.collect():\n",
        "  \n",
        "  mapped_rdd = train_rdd.mapPartitions(lambda iterator: map_partition(iterator, t))\n",
        "  #print(mapped_rdd.collect())\n",
        "  sum = mapped_rdd.reduce(lambda x, y: (knn_reducer(x, y)))\n",
        "  \n",
        "  \n",
        "  sorted_list = sorted(sum[1])\n",
        "  predicted.append(sum[1][sorted_list[0]])\n",
        "  truePred.append(t[11])\n",
        "  \n",
        " \n",
        "# Reduce the nearest neighbors from each partition\n",
        "# neighbors = neighbors_rdd.reduce(lambda x, y: knn_reducer(x, y))\n",
        "\n",
        "# # Print the k nearest neighbors and their distances\n",
        "# print(neighbors)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tGLHppd0BFNt"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import classification_report\n",
        "print(np.sum(truePred))\n",
        "\n",
        "print(classification_report(predicted,truePred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s-Ls5N34OXh0"
      },
      "outputs": [],
      "source": [
        "from pyspark.ml.classification import LogisticRegression\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.classification import RandomForestClassifier\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y23T1AicP_FP"
      },
      "outputs": [],
      "source": [
        "rf = RandomForestClassifier(labelCol=\"is_fraud\", featuresCol=\"features\", numTrees=10)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sw2t1I4QQt0X"
      },
      "outputs": [],
      "source": [
        "model = rf.fit(trainDF)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SfRqirz3S0X-"
      },
      "outputs": [],
      "source": [
        "predictions = model.transform(testDF)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QsHgZLXQS8BL"
      },
      "outputs": [],
      "source": [
        "evaluator = MulticlassClassificationEvaluator(labelCol=\"is_fraud\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
        "accuracy = evaluator.evaluate(predictions)\n",
        "print(\"Accuracy = %g\" % accuracy)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SpxiK33QTqBD"
      },
      "outputs": [],
      "source": [
        "# Calculate precision\n",
        "precision = evaluator.evaluate(predictions, {evaluator.metricName: \"weightedPrecision\"})\n",
        "print(\"Precision: \", precision)\n",
        "\n",
        "# Calculate recall\n",
        "recall = evaluator.evaluate(predictions, {evaluator.metricName: \"weightedRecall\"})\n",
        "print(\"Recall: \", recall)\n",
        "\n",
        "# Calculate F1 score\n",
        "f1score = evaluator.evaluate(predictions, {evaluator.metricName: \"f1\"})\n",
        "print(\"F1 Score: \", f1score)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "99zHqM1zsROd"
      },
      "outputs": [],
      "source": [
        "from pyspark.ml.feature import VectorAssembler\n",
        "from pyspark.ml.classification import LinearSVC\n",
        "\n",
        "from pyspark.sql.functions import col\n",
        "\n",
        "\n",
        "svm = LinearSVC(labelCol=\"is_fraud\", featuresCol=\"features\",maxIter=10, regParam=0.1)\n",
        "svm_model = svm.fit(trainDF)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9ieX5UZbsSQ9"
      },
      "outputs": [],
      "source": [
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "predictions = svm_model.transform(testDF)\n",
        "\n",
        "# Evaluate the model\n",
        "evaluator = MulticlassClassificationEvaluator(labelCol=\"is_fraud\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
        "accuracy = evaluator.evaluate(predictions)\n",
        "print(\"Accuracy = %g\" % accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ipzWC7Cg1y_8"
      },
      "outputs": [],
      "source": [
        "# Calculate precision\n",
        "precision = evaluator.evaluate(predictions, {evaluator.metricName: \"weightedPrecision\"})\n",
        "print(\"Precision: \", precision)\n",
        "\n",
        "# Calculate recall\n",
        "recall = evaluator.evaluate(predictions, {evaluator.metricName: \"weightedRecall\"})\n",
        "print(\"Recall: \", recall)\n",
        "\n",
        "# Calculate F1 score\n",
        "f1score = evaluator.evaluate(predictions, {evaluator.metricName: \"f1\"})\n",
        "print(\"F1 Score: \", f1score)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3b0x6abX9Ssx"
      },
      "outputs": [],
      "source": [
        "from pyspark.ml.classification import LogisticRegression\n",
        "lr = LogisticRegression(labelCol=\"is_fraud\", featuresCol=\"features\")\n",
        "model = lr.fit(trainDF)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hwWEGLuB9Z6-"
      },
      "outputs": [],
      "source": [
        "predictions = model.transform(testDF)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zHyc0zIu9b6q"
      },
      "outputs": [],
      "source": [
        "evaluator = MulticlassClassificationEvaluator(labelCol=\"is_fraud\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
        "accuracy = evaluator.evaluate(predictions)\n",
        "print(\"Accuracy = %g\" % accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EoV25SMM9evk"
      },
      "outputs": [],
      "source": [
        "precision = evaluator.evaluate(predictions, {evaluator.metricName: \"weightedPrecision\"})\n",
        "print(\"Precision: \", precision)\n",
        "\n",
        "# Calculate recall\n",
        "recall = evaluator.evaluate(predictions, {evaluator.metricName: \"weightedRecall\"})\n",
        "print(\"Recall: \", recall)\n",
        "\n",
        "# Calculate F1 score\n",
        "f1score = evaluator.evaluate(predictions, {evaluator.metricName: \"f1\"})\n",
        "print(\"F1 Score: \", f1score)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "gpuType": "T4",
      "private_outputs": true,
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
